{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --upgrade tensorflow --user\n",
    "# !pip install keras --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io, json, talos, itertools\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Embedding, GlobalMaxPool1D, Dropout\n",
    "from keras.layers import Dense, Activation, Embedding, Flatten, GlobalMaxPool1D, Dropout, Conv1D\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with io.open(\"data/train.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    data = f.read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./data/data_train.json\", 'r') as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_WORDS = 5000\n",
    "EMBEDDING_SIZE = 20\n",
    "MAX_LENGTH = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unidecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = list(itertools.chain.from_iterable([[contrib[\"answer\"],contrib[\"question\"] ] for contrib in data]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=MAX_WORDS, lower=True, )\n",
    "tokenizer.fit_on_texts(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sequences_from_list_of_text(text_list):\n",
    "    sequences = tokenizer.texts_to_sequences([unidecode.unidecode(text) for text in text_list])\n",
    "    return pad_sequences(sequences, maxlen=MAX_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_questions = sequences_from_list_of_text([contrib[\"question\"] for contrib in data])\n",
    "data_answers = sequences_from_list_of_text([contrib[\"answer\"] for contrib in data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_tags = [contrib[\"target\"] for contrib in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "all_tags = Counter(itertools.chain.from_iterable(data_tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "sup_100_tags = [key for key, value in dict(all_tags).items() if value >100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "multilabel_binarizer = MultiLabelBinarizer()\n",
    "multilabel_binarizer.fit([sup_100_tags])\n",
    "classes = multilabel_binarizer.classes_\n",
    "y = multilabel_binarizer.transform(data_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_question_train, x_question_test, \\\n",
    "x_answer_train, x_answer_test,\\\n",
    "y_train, y_test = train_test_split(data_questions, data_answers, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 90498 samples, validate on 10056 samples\n",
      "Epoch 1/20\n",
      "90498/90498 [==============================] - 10s 109us/step - loss: 0.0294 - categorical_accuracy: 0.2858 - val_loss: 0.0235 - val_categorical_accuracy: 0.3807\n",
      "Epoch 2/20\n",
      "90498/90498 [==============================] - 9s 99us/step - loss: 0.0238 - categorical_accuracy: 0.3304 - val_loss: 0.0228 - val_categorical_accuracy: 0.3701\n",
      "Epoch 3/20\n",
      "90498/90498 [==============================] - 9s 99us/step - loss: 0.0233 - categorical_accuracy: 0.3438 - val_loss: 0.0221 - val_categorical_accuracy: 0.3614\n",
      "Epoch 4/20\n",
      "90498/90498 [==============================] - 9s 99us/step - loss: 0.0229 - categorical_accuracy: 0.3479 - val_loss: 0.0219 - val_categorical_accuracy: 0.3770\n",
      "Epoch 5/20\n",
      "90498/90498 [==============================] - 9s 99us/step - loss: 0.0228 - categorical_accuracy: 0.3520 - val_loss: 0.0226 - val_categorical_accuracy: 0.3856\n",
      "Epoch 6/20\n",
      "90498/90498 [==============================] - 9s 99us/step - loss: 0.0223 - categorical_accuracy: 0.3637 - val_loss: 0.0211 - val_categorical_accuracy: 0.4055\n",
      "Epoch 7/20\n",
      "90498/90498 [==============================] - 9s 99us/step - loss: 0.0218 - categorical_accuracy: 0.3725 - val_loss: 0.0205 - val_categorical_accuracy: 0.3979\n",
      "Epoch 8/20\n",
      "90498/90498 [==============================] - 9s 99us/step - loss: 0.0216 - categorical_accuracy: 0.3760 - val_loss: 0.0203 - val_categorical_accuracy: 0.4036\n",
      "Epoch 9/20\n",
      "90498/90498 [==============================] - 9s 99us/step - loss: 0.0214 - categorical_accuracy: 0.3818 - val_loss: 0.0202 - val_categorical_accuracy: 0.4155\n",
      "Epoch 10/20\n",
      "90498/90498 [==============================] - 9s 99us/step - loss: 0.0212 - categorical_accuracy: 0.3846 - val_loss: 0.0202 - val_categorical_accuracy: 0.4193\n",
      "Epoch 11/20\n",
      "90498/90498 [==============================] - 9s 99us/step - loss: 0.0212 - categorical_accuracy: 0.3852 - val_loss: 0.0200 - val_categorical_accuracy: 0.3943\n",
      "Epoch 12/20\n",
      "90498/90498 [==============================] - 9s 99us/step - loss: 0.0212 - categorical_accuracy: 0.3881 - val_loss: 0.0202 - val_categorical_accuracy: 0.4167\n",
      "Epoch 13/20\n",
      "90498/90498 [==============================] - 9s 100us/step - loss: 0.0211 - categorical_accuracy: 0.3910 - val_loss: 0.0200 - val_categorical_accuracy: 0.4045\n",
      "Epoch 14/20\n",
      "90498/90498 [==============================] - 9s 100us/step - loss: 0.0211 - categorical_accuracy: 0.3925 - val_loss: 0.0200 - val_categorical_accuracy: 0.4123\n",
      "Epoch 15/20\n",
      "90498/90498 [==============================] - 9s 100us/step - loss: 0.0210 - categorical_accuracy: 0.3970 - val_loss: 0.0202 - val_categorical_accuracy: 0.4568\n",
      "Epoch 16/20\n",
      "26656/90498 [=======>......................] - ETA: 6s - loss: 0.0207 - categorical_accuracy: 0.4050"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(MAX_WORDS, EMBEDDING_SIZE, input_length=MAX_LENGTH))\n",
    "model.add(Dropout(0.15))\n",
    "model.add(GlobalMaxPool1D())\n",
    "model.add(Dense(len(classes), activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer=Adam(0.015), loss='binary_crossentropy', metrics=['categorical_accuracy'])\n",
    "callbacks = [\n",
    "    ReduceLROnPlateau(),\n",
    "    EarlyStopping(patience=4),\n",
    "    ModelCheckpoint(filepath='model-simple.h5', save_best_only=True)\n",
    "]\n",
    "\n",
    "history = model.fit(x_answer_train, y_train,\n",
    "                    epochs=20,\n",
    "                    batch_size=32,\n",
    "                    validation_split=0.1,\n",
    "                    callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_model = load_model('model-simple.h5')\n",
    "metrics = simple_model.evaluate(x_answer_test, y_test)\n",
    "print(\"{}: {}\".format(simple_model.metrics_names[0], metrics[0]))\n",
    "print(\"{}: {}\".format(simple_model.metrics_names[1], metrics[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_length = 300\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(MAX_WORDS, EMBEDDING_SIZE, input_length=MAX_LENGTH))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Conv1D(filter_length, 3, padding='valid', activation='relu', strides=1))\n",
    "model.add(GlobalMaxPool1D())\n",
    "model.add(Dense(len(classes)))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['categorical_accuracy'])\n",
    "model.summary()\n",
    "\n",
    "callbacks = [\n",
    "    ReduceLROnPlateau(),\n",
    "    EarlyStopping(patience=4),\n",
    "    ModelCheckpoint(filepath='model-conv1d.h5', save_best_only=True)\n",
    "]\n",
    "\n",
    "history = model.fit(x_answer_train, y_train,\n",
    "                    epochs=20,\n",
    "                    batch_size=32,\n",
    "                    validation_split=0.1,\n",
    "                    callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model = load_model('model-conv1d.h5')\n",
    "metrics = cnn_model.evaluate(x_answer_test, y_test)\n",
    "print(\"{}: {}\".format(model.metrics_names[0], metrics[0]))\n",
    "print(\"{}: {}\".format(model.metrics_names[1], metrics[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(text):\n",
    "    tokens = tokenizer.texts_to_sequences([text])\n",
    "    return pad_sequences(tokens, maxlen=MAX_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = get_features(\"Il suffit de cesser la destruction des services publics de proximité pour des raisons financières. De plus, ces fermetures sont imposées par l'UE, qui oblige les états a privatiser tous les services publics( poste, hôpitaux, énergie...) , accentuant le désir de rentabilité des services publics actuels.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(zip(classes , cnn_model.predict(features)[0]), key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Siameese "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Concatenate, concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_SIZE = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_input = Input(shape=(MAX_LENGTH,))\n",
    "answer_input = Input(shape=(MAX_LENGTH,))\n",
    "\n",
    "x_question = Embedding(MAX_WORDS, EMBEDDING_SIZE, input_length=MAX_LENGTH)(question_input)\n",
    "\n",
    "x_question = Dropout(0.1)(x_question)\n",
    "x_question = Conv1D(200, 3, padding='valid', activation='relu', strides=1)(x_question)\n",
    "x_question = GlobalMaxPool1D()(x_question)\n",
    "x_question = Dense(100)(x_question)\n",
    "\n",
    "x_answers = Embedding(MAX_WORDS, EMBEDDING_SIZE, input_length=MAX_LENGTH)(answer_input)\n",
    "x_answers = Dropout(0.1)(x_answers)\n",
    "x_answers = Conv1D(200, 3, padding='valid', activation='relu', strides=1)(x_answers)\n",
    "x_answers = GlobalMaxPool1D()(x_answers)\n",
    "x_answers = Dense(100)(x_answers)\n",
    "\n",
    "x = Concatenate(axis=1)([x_question, x_answers])\n",
    "x = Dropout(0.1)(x)\n",
    "x = Dense(100)(x)\n",
    "x = Dropout(0.1)(x)\n",
    "\n",
    "output = Dense(len(classes), activation=\"softmax\")(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model([question_input, answer_input],\n",
    "                output)\n",
    "\n",
    "model.compile(optimizer=\"adam\",\n",
    "               loss='binary_crossentropy', metrics=['categorical_accuracy'],\n",
    "                )\n",
    "\n",
    "model.fit([x_question_train, x_answer_train], y_train, batch_size=32,\n",
    "          epochs=20,\n",
    "                validation_split=0.1,\n",
    "                callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = model.evaluate([x_question_test, x_answer_test], y_test)\n",
    "print(\"{}: {}\".format(model.metrics_names[0], metrics[0]))\n",
    "print(\"{}: {}\".format(model.metrics_names[1], metrics[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_question = \"Que pensez-vous de la situation en France aujourd'hui et de la politique migratoire ? Quels sont, selon vous, les critères à mettre en place pour définir la politique migratoire ? 3 064\"\n",
    "test_answer = \"Vaste question, pas de réponse, on ne peux ni accueillir la misère du monde, ni faire preuve d'apathie...\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_test_question = sequences_from_list_of_text([test_question])\n",
    "feature_test_answer = sequences_from_list_of_text([test_answer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction =  model.predict([feature_test_question, feature_test_answer])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(sorted(zip(multilabel_binarizer.classes_, prediction), key= lambda x: x[1], reverse=True))[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimisations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'OPTIMIZER': ['Nadam', 'Adam'],\n",
    "    'EMBEDDING_SIZE': [20, 50, 100],\n",
    "    'KERNEL_SIZE': [2, 3],\n",
    "    'FILTER_SIZE': [100, 200, 300],\n",
    "    \"ACTIVATION_TYPE\": [\"sigmoid\", \"softmax\"]\n",
    "}\n",
    "\n",
    "def build_model(x_train, y_train, x_val, y_val, params):\n",
    "\n",
    "        model = Sequential()\n",
    "        model.add(Embedding(MAX_WORDS, params[\"EMBEDDING_SIZE\"], input_length=MAX_LENGTH))\n",
    "        model.add(Dropout(0.1))\n",
    "        model.add(Conv1D(params[\"FILTER_SIZE\"], params[\"KERNEL_SIZE\"], padding='valid', activation='relu', strides=1))\n",
    "        model.add(GlobalMaxPool1D())\n",
    "        model.add(Dense(len(classes)))\n",
    "        model.add(Activation(params[\"ACTIVATION_TYPE\"]))\n",
    "        \n",
    "        model.compile(optimizer=params[\"OPTIMIZER\"], loss='binary_crossentropy', metrics=['categorical_accuracy'])\n",
    "\n",
    "        callbacks = [\n",
    "            ReduceLROnPlateau(),\n",
    "            EarlyStopping(patience=4),\n",
    "            ModelCheckpoint(filepath='model-conv1d.h5', save_best_only=True)\n",
    "        ]\n",
    "        \n",
    "        out = model.fit(x_train,\n",
    "                        y_train,\n",
    "                        epochs=20,\n",
    "                        batch_size=32,\n",
    "                        validation_split=0.1,\n",
    "                        callbacks=callbacks)\n",
    "\n",
    "        return out, model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/7 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 79186 samples, validate on 8799 samples\n",
      "Epoch 1/20\n",
      "79186/79186 [==============================] - 23s 285us/step - loss: 0.0228 - categorical_accuracy: 0.4041 - val_loss: 0.0178 - val_categorical_accuracy: 0.5547\n",
      "Epoch 2/20\n",
      "79186/79186 [==============================] - 21s 270us/step - loss: 0.0168 - categorical_accuracy: 0.5531 - val_loss: 0.0160 - val_categorical_accuracy: 0.5930\n",
      "Epoch 3/20\n",
      "79186/79186 [==============================] - 21s 270us/step - loss: 0.0155 - categorical_accuracy: 0.5764 - val_loss: 0.0155 - val_categorical_accuracy: 0.6015\n",
      "Epoch 4/20\n",
      "79186/79186 [==============================] - 21s 270us/step - loss: 0.0148 - categorical_accuracy: 0.5901 - val_loss: 0.0150 - val_categorical_accuracy: 0.6152\n",
      "Epoch 5/20\n",
      "79186/79186 [==============================] - 21s 271us/step - loss: 0.0143 - categorical_accuracy: 0.5989 - val_loss: 0.0148 - val_categorical_accuracy: 0.6076\n",
      "Epoch 6/20\n",
      "79186/79186 [==============================] - 21s 271us/step - loss: 0.0139 - categorical_accuracy: 0.6038 - val_loss: 0.0148 - val_categorical_accuracy: 0.6003\n",
      "Epoch 7/20\n",
      "79186/79186 [==============================] - 21s 270us/step - loss: 0.0137 - categorical_accuracy: 0.6076 - val_loss: 0.0147 - val_categorical_accuracy: 0.6277\n",
      "Epoch 8/20\n",
      "79186/79186 [==============================] - 21s 271us/step - loss: 0.0134 - categorical_accuracy: 0.6100 - val_loss: 0.0147 - val_categorical_accuracy: 0.5992\n",
      "Epoch 9/20\n",
      "79186/79186 [==============================] - 21s 270us/step - loss: 0.0132 - categorical_accuracy: 0.6142 - val_loss: 0.0146 - val_categorical_accuracy: 0.5962\n",
      "Epoch 10/20\n",
      "79186/79186 [==============================] - 21s 271us/step - loss: 0.0130 - categorical_accuracy: 0.6149 - val_loss: 0.0147 - val_categorical_accuracy: 0.5997\n",
      "Epoch 11/20\n",
      "79186/79186 [==============================] - 21s 271us/step - loss: 0.0128 - categorical_accuracy: 0.6183 - val_loss: 0.0148 - val_categorical_accuracy: 0.6050\n",
      "Epoch 12/20\n",
      "79186/79186 [==============================] - 21s 270us/step - loss: 0.0127 - categorical_accuracy: 0.6199 - val_loss: 0.0147 - val_categorical_accuracy: 0.5950\n",
      "Epoch 13/20\n",
      "79186/79186 [==============================] - 21s 271us/step - loss: 0.0126 - categorical_accuracy: 0.6226 - val_loss: 0.0148 - val_categorical_accuracy: 0.5850\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 14%|█▍        | 1/7 [04:41<28:07, 281.23s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 79186 samples, validate on 8799 samples\n",
      "Epoch 1/20\n",
      "79186/79186 [==============================] - 32s 403us/step - loss: 0.0318 - categorical_accuracy: 0.2977 - val_loss: 0.0194 - val_categorical_accuracy: 0.4664\n",
      "Epoch 2/20\n",
      "79186/79186 [==============================] - 32s 400us/step - loss: 0.0176 - categorical_accuracy: 0.4941 - val_loss: 0.0170 - val_categorical_accuracy: 0.5249\n",
      "Epoch 3/20\n",
      "79186/79186 [==============================] - 32s 399us/step - loss: 0.0155 - categorical_accuracy: 0.5361 - val_loss: 0.0154 - val_categorical_accuracy: 0.5432\n",
      "Epoch 4/20\n",
      "79186/79186 [==============================] - 32s 400us/step - loss: 0.0143 - categorical_accuracy: 0.5614 - val_loss: 0.0149 - val_categorical_accuracy: 0.5765\n",
      "Epoch 5/20\n",
      "79186/79186 [==============================] - 32s 400us/step - loss: 0.0136 - categorical_accuracy: 0.5758 - val_loss: 0.0157 - val_categorical_accuracy: 0.5990\n",
      "Epoch 6/20\n",
      "79186/79186 [==============================] - 32s 400us/step - loss: 0.0129 - categorical_accuracy: 0.5864 - val_loss: 0.0140 - val_categorical_accuracy: 0.5862\n",
      "Epoch 7/20\n",
      "79186/79186 [==============================] - 32s 400us/step - loss: 0.0124 - categorical_accuracy: 0.5946 - val_loss: 0.0138 - val_categorical_accuracy: 0.5917\n",
      "Epoch 8/20\n",
      "79186/79186 [==============================] - 32s 404us/step - loss: 0.0120 - categorical_accuracy: 0.5997 - val_loss: 0.0141 - val_categorical_accuracy: 0.5954\n",
      "Epoch 9/20\n",
      "79186/79186 [==============================] - 32s 408us/step - loss: 0.0117 - categorical_accuracy: 0.6070 - val_loss: 0.0148 - val_categorical_accuracy: 0.6011\n",
      "Epoch 10/20\n",
      "79186/79186 [==============================] - 32s 402us/step - loss: 0.0113 - categorical_accuracy: 0.6117 - val_loss: 0.0142 - val_categorical_accuracy: 0.6254\n",
      "Epoch 11/20\n",
      "79186/79186 [==============================] - 32s 401us/step - loss: 0.0110 - categorical_accuracy: 0.6169 - val_loss: 0.0145 - val_categorical_accuracy: 0.6031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 29%|██▊       | 2/7 [10:32<25:10, 302.13s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 79186 samples, validate on 8799 samples\n",
      "Epoch 1/20\n",
      "79186/79186 [==============================] - 19s 236us/step - loss: 0.0304 - categorical_accuracy: 0.2745 - val_loss: 0.0221 - val_categorical_accuracy: 0.4504\n",
      "Epoch 2/20\n",
      "79186/79186 [==============================] - 18s 233us/step - loss: 0.0192 - categorical_accuracy: 0.4742 - val_loss: 0.0204 - val_categorical_accuracy: 0.5057\n",
      "Epoch 3/20\n",
      "79186/79186 [==============================] - 18s 233us/step - loss: 0.0165 - categorical_accuracy: 0.5276 - val_loss: 0.0186 - val_categorical_accuracy: 0.5576\n",
      "Epoch 4/20\n",
      "79186/79186 [==============================] - 18s 233us/step - loss: 0.0149 - categorical_accuracy: 0.5563 - val_loss: 0.0183 - val_categorical_accuracy: 0.5687\n",
      "Epoch 5/20\n",
      "79186/79186 [==============================] - 18s 232us/step - loss: 0.0140 - categorical_accuracy: 0.5739 - val_loss: 0.0207 - val_categorical_accuracy: 0.6072\n",
      "Epoch 6/20\n",
      "79186/79186 [==============================] - 19s 234us/step - loss: 0.0134 - categorical_accuracy: 0.5828 - val_loss: 0.0194 - val_categorical_accuracy: 0.6093\n",
      "Epoch 7/20\n",
      "79186/79186 [==============================] - 19s 238us/step - loss: 0.0129 - categorical_accuracy: 0.5906 - val_loss: 0.0179 - val_categorical_accuracy: 0.6078\n",
      "Epoch 8/20\n",
      "79186/79186 [==============================] - 19s 238us/step - loss: 0.0125 - categorical_accuracy: 0.5948 - val_loss: 0.0188 - val_categorical_accuracy: 0.6072\n",
      "Epoch 9/20\n",
      "79186/79186 [==============================] - 20s 254us/step - loss: 0.0122 - categorical_accuracy: 0.6019 - val_loss: 0.0200 - val_categorical_accuracy: 0.6011\n",
      "Epoch 10/20\n",
      "79186/79186 [==============================] - 19s 235us/step - loss: 0.0119 - categorical_accuracy: 0.6066 - val_loss: 0.0202 - val_categorical_accuracy: 0.6047\n",
      "Epoch 11/20\n",
      "79186/79186 [==============================] - 18s 233us/step - loss: 0.0117 - categorical_accuracy: 0.6089 - val_loss: 0.0210 - val_categorical_accuracy: 0.6213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 43%|████▎     | 3/7 [13:58<18:13, 273.37s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 79186 samples, validate on 8799 samples\n",
      "Epoch 1/20\n",
      "79186/79186 [==============================] - 30s 375us/step - loss: 0.0261 - categorical_accuracy: 0.3614 - val_loss: 0.0183 - val_categorical_accuracy: 0.5001\n",
      "Epoch 2/20\n",
      "79186/79186 [==============================] - 31s 388us/step - loss: 0.0160 - categorical_accuracy: 0.5333 - val_loss: 0.0168 - val_categorical_accuracy: 0.5807\n",
      "Epoch 3/20\n",
      "79186/79186 [==============================] - 30s 375us/step - loss: 0.0140 - categorical_accuracy: 0.5725 - val_loss: 0.0159 - val_categorical_accuracy: 0.5848\n",
      "Epoch 4/20\n",
      "79186/79186 [==============================] - 29s 371us/step - loss: 0.0129 - categorical_accuracy: 0.5923 - val_loss: 0.0150 - val_categorical_accuracy: 0.5953\n",
      "Epoch 5/20\n",
      "79186/79186 [==============================] - 30s 375us/step - loss: 0.0122 - categorical_accuracy: 0.6046 - val_loss: 0.0162 - val_categorical_accuracy: 0.6201\n",
      "Epoch 6/20\n",
      "79186/79186 [==============================] - 31s 387us/step - loss: 0.0117 - categorical_accuracy: 0.6121 - val_loss: 0.0158 - val_categorical_accuracy: 0.6030\n",
      "Epoch 7/20\n",
      "79186/79186 [==============================] - 29s 369us/step - loss: 0.0113 - categorical_accuracy: 0.6162 - val_loss: 0.0152 - val_categorical_accuracy: 0.6113\n",
      "Epoch 8/20\n",
      "79186/79186 [==============================] - 29s 368us/step - loss: 0.0110 - categorical_accuracy: 0.6240 - val_loss: 0.0149 - val_categorical_accuracy: 0.6319\n",
      "Epoch 9/20\n",
      "79186/79186 [==============================] - 29s 368us/step - loss: 0.0106 - categorical_accuracy: 0.6276 - val_loss: 0.0157 - val_categorical_accuracy: 0.6331\n",
      "Epoch 10/20\n",
      "79186/79186 [==============================] - 29s 368us/step - loss: 0.0103 - categorical_accuracy: 0.6299 - val_loss: 0.0144 - val_categorical_accuracy: 0.6254\n",
      "Epoch 11/20\n",
      "79186/79186 [==============================] - 29s 369us/step - loss: 0.0101 - categorical_accuracy: 0.6331 - val_loss: 0.0156 - val_categorical_accuracy: 0.6254\n",
      "Epoch 12/20\n",
      "79186/79186 [==============================] - 29s 369us/step - loss: 0.0099 - categorical_accuracy: 0.6347 - val_loss: 0.0163 - val_categorical_accuracy: 0.6031\n",
      "Epoch 13/20\n",
      "79186/79186 [==============================] - 29s 369us/step - loss: 0.0097 - categorical_accuracy: 0.6380 - val_loss: 0.0154 - val_categorical_accuracy: 0.6083\n",
      "Epoch 14/20\n",
      "79186/79186 [==============================] - 29s 368us/step - loss: 0.0095 - categorical_accuracy: 0.6394 - val_loss: 0.0149 - val_categorical_accuracy: 0.6098\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 57%|█████▋    | 4/7 [20:52<15:46, 315.55s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 79186 samples, validate on 8799 samples\n",
      "Epoch 1/20\n",
      "79186/79186 [==============================] - 29s 368us/step - loss: 0.0317 - categorical_accuracy: 0.2852 - val_loss: 0.0195 - val_categorical_accuracy: 0.4761\n",
      "Epoch 2/20\n",
      "79186/79186 [==============================] - 29s 366us/step - loss: 0.0176 - categorical_accuracy: 0.4977 - val_loss: 0.0164 - val_categorical_accuracy: 0.5557\n",
      "Epoch 3/20\n",
      "79186/79186 [==============================] - 29s 365us/step - loss: 0.0153 - categorical_accuracy: 0.5429 - val_loss: 0.0158 - val_categorical_accuracy: 0.5672\n",
      "Epoch 4/20\n",
      "79186/79186 [==============================] - 29s 365us/step - loss: 0.0140 - categorical_accuracy: 0.5672 - val_loss: 0.0150 - val_categorical_accuracy: 0.5818\n",
      "Epoch 5/20\n",
      "79186/79186 [==============================] - 29s 366us/step - loss: 0.0132 - categorical_accuracy: 0.5842 - val_loss: 0.0143 - val_categorical_accuracy: 0.5885\n",
      "Epoch 6/20\n",
      "79186/79186 [==============================] - 29s 366us/step - loss: 0.0126 - categorical_accuracy: 0.5949 - val_loss: 0.0154 - val_categorical_accuracy: 0.5982\n",
      "Epoch 7/20\n",
      "79186/79186 [==============================] - 31s 392us/step - loss: 0.0121 - categorical_accuracy: 0.6028 - val_loss: 0.0144 - val_categorical_accuracy: 0.6219\n",
      "Epoch 8/20\n",
      "79186/79186 [==============================] - 29s 366us/step - loss: 0.0117 - categorical_accuracy: 0.6097 - val_loss: 0.0150 - val_categorical_accuracy: 0.6040\n",
      "Epoch 9/20\n",
      "79186/79186 [==============================] - 29s 372us/step - loss: 0.0113 - categorical_accuracy: 0.6139 - val_loss: 0.0149 - val_categorical_accuracy: 0.6108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 71%|███████▏  | 5/7 [25:16<10:00, 300.01s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 79186 samples, validate on 8799 samples\n",
      "Epoch 1/20\n",
      "79186/79186 [==============================] - 80s 1ms/step - loss: 0.0239 - categorical_accuracy: 0.4183 - val_loss: 0.0185 - val_categorical_accuracy: 0.5467\n",
      "Epoch 2/20\n",
      "79186/79186 [==============================] - 94s 1ms/step - loss: 0.0154 - categorical_accuracy: 0.5497 - val_loss: 0.0180 - val_categorical_accuracy: 0.5859\n",
      "Epoch 3/20\n",
      "79186/79186 [==============================] - 94s 1ms/step - loss: 0.0140 - categorical_accuracy: 0.5768 - val_loss: 0.0175 - val_categorical_accuracy: 0.6015\n",
      "Epoch 4/20\n",
      "79186/79186 [==============================] - 92s 1ms/step - loss: 0.0130 - categorical_accuracy: 0.5917 - val_loss: 0.0193 - val_categorical_accuracy: 0.6035\n",
      "Epoch 5/20\n",
      "79186/79186 [==============================] - 94s 1ms/step - loss: 0.0124 - categorical_accuracy: 0.6033 - val_loss: 0.0202 - val_categorical_accuracy: 0.6312\n",
      "Epoch 6/20\n",
      "79186/79186 [==============================] - 93s 1ms/step - loss: 0.0119 - categorical_accuracy: 0.6088 - val_loss: 0.0191 - val_categorical_accuracy: 0.6121\n",
      "Epoch 7/20\n",
      "79186/79186 [==============================] - 93s 1ms/step - loss: 0.0115 - categorical_accuracy: 0.6142 - val_loss: 0.0213 - val_categorical_accuracy: 0.5979\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 86%|████████▌ | 6/7 [35:57<06:42, 402.29s/it]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 79186 samples, validate on 8799 samples\n",
      "Epoch 1/20\n",
      "79186/79186 [==============================] - 92s 1ms/step - loss: 0.0295 - categorical_accuracy: 0.3430 - val_loss: 0.0187 - val_categorical_accuracy: 0.5110\n",
      "Epoch 2/20\n",
      "79186/79186 [==============================] - 93s 1ms/step - loss: 0.0160 - categorical_accuracy: 0.5380 - val_loss: 0.0156 - val_categorical_accuracy: 0.5746\n",
      "Epoch 3/20\n",
      "79186/79186 [==============================] - 93s 1ms/step - loss: 0.0141 - categorical_accuracy: 0.5683 - val_loss: 0.0146 - val_categorical_accuracy: 0.6020\n",
      "Epoch 4/20\n",
      "79186/79186 [==============================] - 92s 1ms/step - loss: 0.0132 - categorical_accuracy: 0.5842 - val_loss: 0.0151 - val_categorical_accuracy: 0.5860\n",
      "Epoch 5/20\n",
      "79186/79186 [==============================] - 93s 1ms/step - loss: 0.0125 - categorical_accuracy: 0.5954 - val_loss: 0.0156 - val_categorical_accuracy: 0.5968\n",
      "Epoch 6/20\n",
      "79186/79186 [==============================] - 98s 1ms/step - loss: 0.0120 - categorical_accuracy: 0.6049 - val_loss: 0.0164 - val_categorical_accuracy: 0.6177\n",
      "Epoch 7/20\n",
      "79186/79186 [==============================] - 92s 1ms/step - loss: 0.0116 - categorical_accuracy: 0.6095 - val_loss: 0.0148 - val_categorical_accuracy: 0.6003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "100%|██████████| 7/7 [46:50<00:00, 477.69s/it]\u001b[A"
     ]
    }
   ],
   "source": [
    "scan_object = talos.Scan(x, y, model=build_model, params=params, grid_downsample=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "complete_time            03/11/19/16:23\n",
       "experiment_name           031119153617_\n",
       "grid_downsample                     0.1\n",
       "random_method          uniform_mersenne\n",
       "reduce_loss                       False\n",
       "reduction_interval                   50\n",
       "reduction_method                   None\n",
       "reduction_metric                val_acc\n",
       "reduction_threshold                 0.2\n",
       "reduction_window                     20\n",
       "x_shape                   (125693, 200)\n",
       "y_shape                   (125693, 307)\n",
       "dtype: object"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scan_object.details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x7f26a83eb908>"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scan_object.best_model(metric=\"val_categorical_accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = get_features(\"Il suffit de cesser la destruction des services publics de proximité pour des raisons financières. De plus, ces fermetures sont imposées par l'UE, qui oblige les états a privatiser tous les services publics( poste, hôpitaux, énergie...) , accentuant le désir de rentabilité des services publics actuels.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = scan_object.best_model(metric=\"val_categorical_accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction_tags(features):\n",
    "    return sorted(zip(classes , best_model.predict(features)[0]), key=lambda x: x[1], reverse=True)[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Z_Autres', 0.23051563),\n",
       " ('Sans_réponse_/_Hors_sujet_/_Inclassable', 0.21212253),\n",
       " ('A_Aucune', 0.10980064),\n",
       " ('A_Aucun,_ou_la_réduire', 0.0658187),\n",
       " ('A_Aucun', 0.058471948),\n",
       " ('Communes,_intercommunalités', 0.039815485),\n",
       " ('B_>_Les_4,_tout_est_lié', 0.036506474),\n",
       " ('Collectivités_locales', 0.03515768),\n",
       " ('Simple_décompte_informatif_(actuel)', 0.027210295),\n",
       " ('Compter_comme_exprimé', 0.026890397)]"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_prediction_tags(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.00256705e-03, 1.95088983e-03, 2.37703323e-04, 5.95143437e-03,\n",
       "       5.84719479e-02, 6.58186972e-02, 7.00008869e-03, 1.09800637e-01,\n",
       "       1.61245465e-03, 4.67148423e-03, 1.10518932e-03, 1.48117542e-04,\n",
       "       9.97066498e-04, 8.65161419e-05, 7.77244568e-05, 4.30643559e-05,\n",
       "       3.33845615e-04, 1.47101283e-03, 8.64326954e-04, 1.01268291e-04,\n",
       "       1.37299299e-04, 7.73876905e-04, 3.45498323e-04, 1.95443630e-04,\n",
       "       2.46730447e-03, 3.74785066e-03, 7.32392073e-04, 1.40041113e-04,\n",
       "       2.44408846e-04, 2.37083435e-03, 1.33395195e-04, 1.41367316e-03,\n",
       "       6.81817532e-04, 3.53753567e-05, 4.47630882e-05, 3.65064740e-02,\n",
       "       1.26600266e-04, 2.98857689e-03, 1.72555447e-05, 4.55945730e-04,\n",
       "       4.31835651e-05, 8.83936882e-03, 2.69711018e-05, 1.44715309e-02,\n",
       "       3.61502171e-05, 6.91711903e-05, 1.79138780e-03, 3.27557325e-04,\n",
       "       3.61427665e-03, 7.78764486e-04, 3.30448151e-04, 3.51576805e-02,\n",
       "       3.98154855e-02, 2.68903971e-02, 2.17854977e-05, 7.42167234e-03,\n",
       "       5.00589609e-04, 2.00688839e-04, 2.37044692e-03, 1.15841627e-04,\n",
       "       6.57230616e-04, 4.09305096e-04, 5.54054976e-04, 1.91330910e-03,\n",
       "       5.70416451e-05, 3.76313925e-04, 6.81936741e-04, 6.89715147e-04,\n",
       "       4.29692864e-03, 7.21216202e-05, 1.24692917e-04, 3.62098217e-05,\n",
       "       9.79462266e-03, 8.30292702e-05, 8.38994980e-04, 6.50912523e-04,\n",
       "       7.39485025e-04, 9.44274664e-03, 5.48112392e-03, 5.55217266e-05,\n",
       "       4.89920378e-04, 1.19509399e-02, 2.30818987e-04, 1.48987770e-03,\n",
       "       1.48355961e-04, 2.64853239e-04, 1.52736902e-03, 1.18628144e-03,\n",
       "       1.73598528e-04, 5.32716513e-04, 3.66270542e-04, 8.00067186e-03,\n",
       "       4.23550606e-04, 1.49399042e-04, 3.60810757e-03, 1.44974291e-02,\n",
       "       2.75132060e-03, 5.59091568e-04, 7.33852386e-04, 3.49816680e-03,\n",
       "       9.85264778e-05, 5.60298562e-03, 2.95251608e-04, 9.34690237e-04,\n",
       "       5.67585230e-04, 1.62360072e-03, 3.85463238e-03, 5.71876764e-04,\n",
       "       9.03010368e-06, 9.72467661e-03, 3.07419896e-03, 2.16421485e-03,\n",
       "       3.30150127e-04, 2.22027302e-05, 4.66704369e-05, 1.78515911e-03,\n",
       "       1.40935183e-03, 1.04904175e-05, 1.25646591e-04, 2.66364217e-03,\n",
       "       4.58836555e-04, 4.84585762e-05, 8.13990831e-04, 2.41577625e-03,\n",
       "       5.84492087e-03, 1.75035000e-03, 3.96066904e-03, 5.04821539e-04,\n",
       "       2.98053026e-04, 4.36306000e-05, 4.25577164e-05, 9.46313143e-04,\n",
       "       6.38872385e-04, 7.20471144e-04, 1.41710043e-04, 2.49087811e-03,\n",
       "       2.04288960e-03, 2.60144472e-03, 6.54637814e-04, 3.27330828e-03,\n",
       "       9.07480717e-05, 1.94519758e-04, 5.66244125e-05, 1.83641911e-04,\n",
       "       2.15411186e-04, 2.70903111e-04, 1.18237734e-03, 2.44736671e-04,\n",
       "       6.92903996e-04, 9.44468379e-03, 1.65909529e-03, 1.55425370e-02,\n",
       "       3.54796648e-04, 6.49988651e-04, 1.02964044e-03, 2.35110521e-04,\n",
       "       1.18997693e-03, 3.27315927e-03, 9.82251763e-03, 1.41152740e-03,\n",
       "       1.18967891e-03, 4.88728285e-04, 3.63290310e-04, 3.48898768e-03,\n",
       "       1.29222870e-04, 1.31660700e-03, 3.22040915e-03, 3.27229500e-05,\n",
       "       9.31441784e-04, 1.41388178e-03, 4.71740961e-03, 1.47573650e-02,\n",
       "       1.30623579e-04, 5.28013706e-03, 1.39147043e-04, 2.43186951e-05,\n",
       "       1.22964382e-03, 1.45703554e-03, 5.77777624e-04, 9.46760178e-04,\n",
       "       1.04615092e-02, 8.59349966e-04, 3.55371833e-03, 8.63075256e-04,\n",
       "       4.94718552e-05, 7.90059566e-05, 2.66879797e-04, 1.26928091e-03,\n",
       "       5.21451235e-04, 1.36265159e-03, 1.79708004e-05, 6.09600544e-03,\n",
       "       3.41236591e-05, 3.65614891e-04, 2.30640173e-04, 6.70552254e-06,\n",
       "       7.27054477e-03, 2.12122530e-01, 9.23633575e-04, 1.42455101e-02,\n",
       "       2.02134252e-03, 1.05124712e-03, 1.14738941e-03, 6.10351562e-04,\n",
       "       3.66866589e-03, 2.72102952e-02, 7.11649656e-04, 3.30239534e-04,\n",
       "       7.46339560e-04, 1.21146441e-04, 2.39625573e-03, 4.17232513e-07,\n",
       "       3.44574451e-04, 4.14779782e-03, 2.44456530e-03, 1.18255615e-04,\n",
       "       4.56899405e-04, 6.32047653e-04, 4.59793210e-03, 9.51871276e-03,\n",
       "       2.07036734e-04, 1.67846680e-04, 1.63823366e-04, 4.98890877e-05,\n",
       "       1.16437674e-04, 6.86645508e-05, 6.96182251e-05, 3.79949808e-04,\n",
       "       1.36166811e-04, 1.83582306e-05, 1.26034021e-04, 4.58061695e-05,\n",
       "       1.52796507e-04, 2.34663486e-04, 2.57790089e-05, 2.46167183e-05,\n",
       "       2.46781111e-03, 7.46548176e-04, 1.78188086e-04, 1.67962909e-03,\n",
       "       4.11182642e-04, 1.78739429e-03, 2.22867727e-03, 8.00639391e-03,\n",
       "       1.29553080e-02, 4.76568937e-04, 9.34600830e-05, 9.18745995e-04,\n",
       "       1.29088759e-03, 4.34815884e-05, 3.01241875e-04, 1.22576952e-04,\n",
       "       8.07642937e-04, 2.86489725e-04, 3.78042459e-04, 3.77655029e-04,\n",
       "       6.05583191e-04, 1.70379877e-04, 2.15172768e-05, 1.79409981e-05,\n",
       "       1.66594982e-05, 1.32620335e-05, 5.98728657e-05, 3.91006470e-05,\n",
       "       1.84646249e-03, 6.69062138e-05, 3.62694263e-05, 6.53266907e-05,\n",
       "       1.18598342e-03, 1.01938844e-03, 3.22163105e-05, 1.27822161e-04,\n",
       "       5.41210175e-05, 1.08352304e-03, 1.51589513e-03, 1.04576349e-04,\n",
       "       8.76903534e-04, 3.72856855e-03, 2.75260210e-03, 1.69610977e-03,\n",
       "       1.11564994e-03, 3.28332186e-04, 8.63403082e-04, 8.26537609e-04,\n",
       "       5.73277473e-04, 6.25848770e-05, 4.23192978e-04, 3.96558642e-03,\n",
       "       1.07220709e-02, 1.92317367e-03, 2.51859426e-04, 2.36332417e-03,\n",
       "       1.65991485e-02, 2.30515629e-01, 7.85171986e-04, 4.37736511e-04,\n",
       "       9.36985016e-05, 2.15739012e-04, 2.09897757e-04, 1.12751126e-03,\n",
       "       4.38404083e-03, 4.98324633e-04, 6.81132078e-04, 5.54740429e-04,\n",
       "       8.48562922e-04, 1.36410212e-03, 3.35962774e-04], dtype=float32)"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.predict(features)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
